{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: import_ipynb in /Users/Simon/opt/anaconda3/lib/python3.7/site-packages (0.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.imputation.mice import MICE, MICEData\n",
    "# import fancyimpute\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#import all the functions we wrote ourselves\n",
    "%pip install import_ipynb\n",
    "import import_ipynb\n",
    "#import Functions as functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_keyfigures_and_Companies(arr1,arr3):\n",
    "    '''\n",
    "    This Dataframe joins keyfigures and companylist using Permno as key\n",
    "    :param arr1: Pandas-Dataframe of keyfigures\n",
    "    :param arr3: Pandas-Dataframe of S&PCompanylist\n",
    "    :return: joint Dataframe on Permno\n",
    "    '''\n",
    "    assert type(arr1)== pd.DataFrame\n",
    "    assert type(arr3) == pd.DataFrame\n",
    "    arr1=pd.DataFrame(arr1)\n",
    "    arr3 = pd.DataFrame(arr3)\n",
    "    arr3=arr3.rename(columns={'PERMNO':'permno'})\n",
    "    output=pd.merge_asof(arr1,arr3,'permno')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key(arr):\n",
    "    '''\n",
    "    This function adds a unique-key to a dataframe so it can be used as identifier of a row. Key = public_date + Ticker\n",
    "    :param arr: pandas dataframe\n",
    "    :return: df + col key out of public-date and TICKER\n",
    "    '''\n",
    "    assert type(arr)==pd.DataFrame\n",
    "    arr=pd.DataFrame(arr)\n",
    "    arr['key'] = arr.public_date.astype(str) + arr.TICKER.astype(str)\n",
    "    arr['key']=arr['key'].astype(str)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_Ratings_and_Rest(rest,arr2):\n",
    "    '''\n",
    "    This function combines the 2 already combined Dataframes with the Ratings using date and ticker\n",
    "    :param rest: Pandas-Dataframe of keyfigures and S&PCompanylist\n",
    "    :param arr2: Pandas-Dataframe of Ratings\n",
    "    :return: joint Pandas-Dataframe of all. Uncleaned\n",
    "    '''\n",
    "    assert type(rest)== pd.DataFrame\n",
    "    assert type(arr2) == pd.DataFrame\n",
    "    rest=pd.DataFrame(rest)\n",
    "    arr2 = pd.DataFrame(arr2)\n",
    "    arr2 = arr2.rename(columns={'tic': 'TICKER'})\n",
    "    arr2['public_date']=arr2['datadate']\n",
    "    #Since the format of the date does not match between the dataframe, they are going to be reformatted first\n",
    "    rest['public_date']=rest['public_date'].astype(str)\n",
    "    rest['public_date'] = rest['public_date'].str.replace(r'/', '')\n",
    "    arr2['public_date'] = arr2['public_date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    rest['public_date'] = rest['public_date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    \n",
    "    #Now that the formats are matching, the function add_key(DATAFRAME) is used, to help merge the 2 Dataframes together\n",
    "    arr2=add_key(arr2)\n",
    "    rest=add_key(rest)\n",
    "    output = rest.merge(arr2, how='left', on=['key'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagging_Ratings_1M(path):\n",
    "    '''\n",
    "    This function creates a nested list of keys and the according rating of the previous month for merging with pandas-df-\n",
    "    :param path: path to csv-file with data\n",
    "    :return: return list with tuple (key, Rating), so it can be merged to Dataframe. Empty values represented by None.\n",
    "    '''\n",
    "    output=[['key', 'Lagging-Rating_1M']]\n",
    "    with open(path,'r') as f:\n",
    "        #create comparision-list:\n",
    "        compdict={}\n",
    "        for line in f.readlines():\n",
    "            li = line.split(',')\n",
    "            Kürzel=str(li[79][:7])+str(li[79][10:])\n",
    "\n",
    "            compdict[Kürzel]=li[81]\n",
    "        f.close()\n",
    "        with open(path,'r') as r:\n",
    "            for line in r.readlines()[1:]:\n",
    "                key=None\n",
    "                lagrating=None\n",
    "                sublis=()\n",
    "                newdate=None\n",
    "                liste=line.split(',')\n",
    "                #create date of previous month of this line\n",
    "                newdate=str(liste[4][:5])+str(liste[4][5:7])\n",
    "\n",
    "                #if month between 01 and 08\n",
    "                if int(liste[4][5:7]) in range(9):\n",
    "                    newdate = str(liste[4][:5]) + '0'+str(int(liste[4][5:7]) + 1)\n",
    "\n",
    "                #if month >=9\n",
    "                elif 11>=int(liste[4][5:7])>=9:\n",
    "                    newdate =str(liste[4][:5])+str(int(liste[4][5:7])+1)\n",
    "\n",
    "                #if month ==12 (We gotta subtract a Year too)\n",
    "                elif int(liste[4][5:7])==12:\n",
    "                    newdate = str(int(liste[4][:4])+1) + '-01'\n",
    "                key = str(liste[4]) + str(liste[74])\n",
    "                newkey=newdate+str(liste[74])\n",
    "                try:\n",
    "                    #If the previous month exists with a rating, use this\n",
    "                    lagrating = compdict[newdate + str(liste[74])]\n",
    "                except KeyError:\n",
    "                    #if there is no previous-month-rating, fill-in None\n",
    "                    lagrating=None\n",
    "                sublis=[key,lagrating]\n",
    "                output.append(sublis)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_iterative_imputer(df):\n",
    "    \"\"\" \n",
    "    Impute the missing values (NaN) with the IterativeImputer\n",
    "    :param df: feature matrix with NaN values to be imputed\n",
    "    :return: imputed Pandas-Dataframe\n",
    "    \"\"\"\n",
    "    from sklearn.experimental import enable_iterative_imputer \n",
    "    from sklearn.impute import IterativeImputer\n",
    "    #Define all column with numeric values (the features)\n",
    "    num_cols = ['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc', 'ps', 'pcf', \n",
    "                'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq',\n",
    "                'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "                'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt', 'int_totdebt', 'cash_lt', 'invt_act',\n",
    "                'rect_act', 'debt_at', 'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct', 'ocf_lct',\n",
    "                'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets', 'debt_capital', 'de_ratio', 'intcov',\n",
    "                'intcov_ratio', 'cash_ratio', 'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "                'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc', 'accrual', 'ptb',\n",
    "                'DIVYIELD', 'PEG_1yrforward', 'PEG_ltgforward']\n",
    "\n",
    "    # Copy df to df_imputed\n",
    "    df_imputed = df[num_cols].copy(deep=True)\n",
    "\n",
    "    # Initialize IterativeImputer\n",
    "    mice_imputer = IterativeImputer(max_iter=20)\n",
    "\n",
    "    # Impute using fit_tranform on df\n",
    "    df_imputed.iloc[:, :] = mice_imputer.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df_imputed.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def feature_selection(x, y, thres):\n",
    "    \"\"\" \n",
    "    Find out, which the most important features are. Return a list of the most important features\n",
    "    which wil be used for the algorithms.\n",
    "    :param x: feature input without NaN values\n",
    "    :param y: classification input\n",
    "    :param thres: input as percentage value, features with relative importance over this value will be in the output \n",
    "    :return: the list of important features\n",
    "    \"\"\"\n",
    "    \n",
    "    feat_labels = x.columns[:]\n",
    "    \n",
    "    # Create Random Forest object, fit data and\n",
    "    # extract feature importance attributes\n",
    "    forest = RandomForestClassifier(random_state=1, class_weight='balanced')\n",
    "    forest.fit(x, y)\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    #Define n as number of importances over the value thres\n",
    "    n = sum(importances > thres)\n",
    "    \n",
    "    # Get cumsum of the n most important features\n",
    "    feat_imp = np.sort(importances)[::-1]\n",
    "    sum_feat_imp = np.cumsum(feat_imp)[:n]\n",
    "    \n",
    "    # Sort output (by relative importance) and \n",
    "    # print top n features\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    for i in range(n):\n",
    "        print('{0:2d}) {1:7s} {2:6.4f}'.format(i + 1, \n",
    "                                           feat_labels[indices[i]],\n",
    "                                           importances[indices[i]]))\n",
    "        \n",
    "    \n",
    "    # Plot Feature Importance (both cumul., individual)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(range(n), importances[indices[:n]], align='center')\n",
    "    plt.xticks(range(n), feat_labels[indices[:n]], rotation=90)\n",
    "    plt.xlim([-1, n])\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Rel. Feature Importance')\n",
    "    plt.step(range(n), sum_feat_imp, where='mid', \n",
    "         label='Cumulative importance')\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    \n",
    "    # Create a list with the important features for ML algorhithms\n",
    "    feature_list = [None] * n\n",
    "    for i in range(n):\n",
    "        feature_list[i] = feat_labels[indices[i]]\n",
    "    \n",
    "    # return the list of important features\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, Y_train):\n",
    "    '''\n",
    "    This function performs a Logistic Regression on the X_train and Y_train and uses grid-cross validation on the datasets.\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :return: Cross-Validation Hyperparameter grid.\n",
    "    '''\n",
    "    lor = LogisticRegression(max_iter=100, tol=0.001,random_state=1, n_jobs=-1,solver='saga',warm_start=True) #increasing iterations to 1000 increases score by only 1% -> it is not worth the additional time\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('logreg', lor)])\n",
    "\n",
    "    param_grid = {'logreg__penalty': ['elasticnet'], #elastic nets combines l1&l2\n",
    "                  'logreg__C':[6,6.5,7,7.5,8],\n",
    "                  'logreg__l1_ratio':[0,0.05,0.1,0.15,0.2,1]} #if 0, or 1 then l2 or l1 would be best. If between then the combination of both\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train,Y_train)\n",
    "    \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_poly(X_train,Y_train):\n",
    "    '''\n",
    "    This function uses Support Vector Machines on X_train and Y_train with a Polynomial Kernel Function.\n",
    "    It uses Grid-Crossvalidation to find the best hyperparameters for the dataset\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :return: Cross-Validation Hyperparameter grid\n",
    "    '''\n",
    "    \n",
    "    # Create pipeline object with standard scaler and SVC estimator\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('svm_poly', SVC(kernel='poly', random_state=0, max_iter=100000))])\n",
    "    # Define parameter grid\n",
    "    param_grid = {'svm_poly__C': [900,1000,1100], \n",
    "                  'svm_poly__degree': [3,4,5],\n",
    "                  'svm_poly__gamma': [0,0.05,0.1],\n",
    "                  'svm_poly__coef0':[0.6]}  #Larger gridsearch yielded 0.6 to be the best coef0 with this combination. As it does not greatly change the cv accuracy(<1%) we don't include it in this grid search to lower the computing time.\n",
    "\n",
    "    # Run grid search\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train, Y_train)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_rbf(X_train,Y_train):\n",
    "    '''\n",
    "    This function uses Support Vector Machines on X_train and Y_train with a Radial Basis Kernel Function(rbf).\n",
    "    It uses Grid-Crossvalidation to find the best hyperparameters for the dataset\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :return: Cross-Validation Hyperparameter grid\n",
    "    '''\n",
    "\n",
    "    # Create pipeline object with standard scaler and SVC estimator\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('svm_rbf', SVC(kernel='rbf', random_state=0, max_iter=100000))])\n",
    "    # Define parameter grid\n",
    "    param_grid = {'svm_rbf__C': [100,150,200], \n",
    "                  'svm_rbf__gamma': [0.25,0.3,0.35]} \n",
    "    # Run grid search\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=-1) #cv=5 yields same accuracy\n",
    "    grid = grid.fit(X_train, Y_train)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_rbf_bal(X_train,Y_train):\n",
    "    '''\n",
    "    This function uses Support Vector Machines on X_train and Y_train with a Radial Basis Kernel Function(rbf).\n",
    "    It uses Grid-Crossvalidation to find the best hyperparameters for the dataset where we use balanced class weights.\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :return: Cross-Validation Hyperparameter grid\n",
    "    '''\n",
    "\n",
    "    # Create pipeline object with standard scaler and SVC estimator\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('svm_rbf', SVC(kernel='rbf', random_state=0, max_iter=100000, class_weight='balanced'))])\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {'svm_rbf__C': [100,200,300], \n",
    "                  'svm_rbf__gamma': [0.25,0.3,0.35]} \n",
    "    # Run grid search\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=-1) #cv=5 yields same accuracy\n",
    "    grid = grid.fit(X_train, Y_train)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, Y_train, n_estimators, maxDepth, minSamplesNode, minSamplesLeaf):\n",
    "    \"\"\" \n",
    "    This function applies Random Forest Classifier on X_train and Y_train and uses grid-cross validation on the datasets.\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :param n_estimators: array of values which will be tested for variable n_estimators\n",
    "    :param maxDepth: array of values which will be tested for variable max_depth\n",
    "    :param minSamplesNode: array of values which will be tested for variable min_samples_split\n",
    "    :param minSamplesLeaf: array of values which will be tested for variable min_samples_leaf\n",
    "    \"\"\"\n",
    "    # Define the hyperparameter values to be tested\n",
    "    param_grid = {\"n_estimators\": n_estimators,\n",
    "                  'max_depth': maxDepth,\n",
    "                  'min_samples_split': minSamplesNode,\n",
    "                  'min_samples_leaf': minSamplesLeaf},\n",
    "\n",
    "    # Run brute-force grid search\n",
    "    grid = GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv= 5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train, Y_train)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural(X_train, Y_train, hidden_layer, maxIter):\n",
    "    \"\"\" \n",
    "    This function applies MLP Classifier on X_train and Y_train and uses grid-cross validation on the datasets.\n",
    "    :param X_train: Training Set of X values\n",
    "    :param Y_train: Training Set of Y values(factorized)\n",
    "    :param hidden_layer: array of values which will be tested for variable hidden_layer_sizes\n",
    "    :param maxIter: array of values which will be tested for variable max_iter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    mlp = MLPClassifier(random_state=0, solver= \"lbfgs\", warm_start= True)\n",
    "    \n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('neural', MLPClassifier())])\n",
    "    \n",
    "    # Define the hyperparameter values to be tested\n",
    "    param_grid = {\"neural__hidden_layer_sizes\" : hidden_layer,\n",
    "                  'neural__max_iter': maxIter},\n",
    "\n",
    "\n",
    "    # Run brute-force grid search\n",
    "    #solver \"lbfgs\" has proven to be the best\n",
    "    grid = GridSearchCV(pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv= 5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train, Y_train)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
